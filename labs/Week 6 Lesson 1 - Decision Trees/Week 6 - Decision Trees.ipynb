{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification and Regression Trees\n",
    "\n",
    "## Tuesday June 27, 2017\n",
    "\n",
    "### Classification\n",
    "\n",
    "In this task we have some data from the HR department of a company. Our goal is to understand why people are leaving and if there's anything we can do to stop the good people from leaving. This will be a classification problem where the category we are trying to predict is 'leave' or 'stay'.\n",
    "\n",
    "The data we have contains the following infromation:\n",
    "\n",
    "- satisfaction_level: How satisfied is an employee with their current role\n",
    "- last_evaluation: How a manager has rated an employees performance\n",
    "- number_project: The number of projects the employee has worked on\n",
    "- average_monthly_hours: The average number of hours they work (billed?) in the month\n",
    "- time_spend_company: Number of years of service.\n",
    "- Work_accident: Whether or not they have had a work accident\n",
    "- left: whether or not an employee left (our y-variable in this case)\n",
    "- promoted_last_5years: Was the employee promoted in the last 5 years\n",
    "- sales: What division the employee worked in\n",
    "- salary: 3-level salary score (low, medium, high)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read data\n",
    "hr_data = pd.read_csv('../../data/HR_comma_sep.csv')\n",
    "hr_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check the unique values for the strings\n",
    "print(data['sales'].unique())\n",
    "\n",
    "print(data['salary'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert categorical columns to binary representations\n",
    "hr_data_with_dummies = pd.get_dummies(data=hr_data, columns = ['sales', 'salary'], prefix = ['sales', 'salary'] )\n",
    "hr_data_with_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot a Correlation Matrix\n",
    "corr = hr_data_with_dummies.corr()\n",
    "corr = (corr)\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)\n",
    "sns.plt.title('Heatmap of Correlation Matrix')\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's make that plot a bit larger\n",
    "plt.figure(figsize = (20,20))\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)\n",
    "sns.plt.title('Heatmap of Correlation Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extract 'left' column, because 'left' is our target value\n",
    "corr_left = pd.DataFrame(corr['left'].drop('left'))\n",
    "corr_left.sort_values(by = 'left', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important !!!\n",
    "The correlation only shows us a linear correlation between variables and you should only use this as a rough guide to gain an understanding of the dataset. This is just an exploratory measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualise the data to understand what might be happening with the employees leaving\n",
    "#time spend with promotion\n",
    "plt.figure(figsize = (10,6))\n",
    "sns.barplot(x='time_spend_company', y = 'left', hue = 'promotion_last_5years', data = hr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualise the data to understand what might be happening with the employees leaving\n",
    "#time spend with promotion\n",
    "plt.figure(figsize = (16,6))\n",
    "sns.barplot(x='sales', y = 'left', data = hr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Boxplot of satisfaction level\n",
    "g = sns.FacetGrid(data, col = 'left')\n",
    "g.map(sns.boxplot, 'satisfaction_level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Boxplot of last evaluation\n",
    "g = sns.FacetGrid(data, col = 'left')\n",
    "g.map(sns.boxplot, 'last_evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,12))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(data.satisfaction_level[data.left == 1],data.last_evaluation[data.left == 1],'o', alpha = 0.1)\n",
    "plt.ylabel('Last Evaluation')\n",
    "plt.title('Employees who left')\n",
    "plt.xlabel('Satisfaction level')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Employees who stayed')\n",
    "plt.plot(data.satisfaction_level[data.left == 0],data.last_evaluation[data.left == 0],'o', alpha = 0.1)\n",
    "plt.xlim([0.4,1])\n",
    "plt.ylabel('Last Evaluation')\n",
    "plt.xlabel('Satisfaction level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train-Test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = hr_data_with_dummies.drop('left', 1)\n",
    "label = hr_data_with_dummies.left\n",
    "data_train, data_test, label_train, label_test = train_test_split(data, label, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "from sklearn import tree\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt.fit(data_train, label_train)\n",
    "dt_score_train = dt.score(data_train, label_train)\n",
    "print(\"Training score: \",dt_score_train)\n",
    "dt_score_test = dt.score(data_test, label_test)\n",
    "print(\"Testing score: \",dt_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "! pip install graphviz\n",
    "! pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "out = StringIO()\n",
    "tree.export_graphviz(dt, out_file = out)\n",
    "# OUTPUT DOT LANGUAGE SCRIPTS\n",
    "print(out.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a feature vector\n",
    "features = hr_data_with_dummies.columns.tolist()\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "tree.export_graphviz(dt, out_file='tree_hr_analysis.dot', feature_names=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising the tree is a bit of a hassle... \n",
    "\n",
    "You can try copying and pasting the tree from the dot output into a tool like,\n",
    "(webgraphviz)[http://www.webgraphviz.com/].\n",
    "\n",
    "- What is the first thing you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's try running this with not as much depth\n",
    "# Decision tree\n",
    "from sklearn import tree\n",
    "dt = tree.DecisionTreeClassifier(random_state=1, max_depth=2)\n",
    "dt.fit(data_train, label_train)\n",
    "dt_score_train = dt.score(data_train, label_train)\n",
    "print(\"Training score: \",dt_score_train)\n",
    "dt_score_test = dt.score(data_test, label_test)\n",
    "print(\"Testing score: \",dt_score_test)\n",
    "\n",
    "# Create a feature vector\n",
    "features = hr_data_with_dummies.columns.tolist()\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "tree.export_graphviz(dt, out_file='tree_hr_analysis_smaller_tree.dot', feature_names=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we've got something that's getting a bit more useful.\n",
    "\n",
    "Answer the following questions:\n",
    "- What's the most important feature?\n",
    "- How do we read the tree?\n",
    "- What are some of the things we could try to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below are some further examples of how classification and regression trees work\n",
    "\n",
    "Run through the examples below and ask if you have any questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Classification and Regression Trees\n",
    "\n",
    "'''\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Read, Explore, and Process data\n",
    "'''\n",
    "\n",
    "# Read in the data\n",
    "titanic = pd.read_csv('../../data/titanic.csv')\n",
    "\n",
    "# Take a  selection of the variables\n",
    "d = titanic[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for missing values in all columns\n",
    "d.isnull().sum()\n",
    "d.groupby(['Sex', 'Pclass']).Age.apply(lambda x: x.isnull().sum()) / d.groupby(['Sex', 'Pclass']).Age.count()\n",
    "\n",
    "# Convert all variables to numeric so for scikit learn\n",
    "d['Sex'] = np.where(d.Sex == 'female', 1, 0)\n",
    "\n",
    "# Fill in missing values with the mean value (hint: use .fillna())\n",
    "d['Age'] = d['Age'].fillna(d['Age'].mean())\n",
    "\n",
    "# Explore the data to identify trends in characteristics of survivors\n",
    "d.Survived.value_counts()                    # How many people lived and died\n",
    "d.Survived.mean()                            # The survival rate for everyone\n",
    "d.groupby('Sex').Survived.mean()             # By Sex: women have higher survival rates\n",
    "d.groupby('Pclass').Survived.mean()          # By Pclass: 1st class passengers have higher survival rates\n",
    "d.groupby(['Sex', 'Pclass']).Survived.mean() # By Sex and Pclass: Women in the 1st and 2nd classes had the highest survival rates\n",
    "\n",
    "# Create a proxy variable representing whether the Spouse was on board\n",
    "d['Spouse'] = ((d.Age > 18) & (d.SibSp >= 1)).astype(int)\n",
    "d.Spouse.value_counts()\n",
    "d.groupby(['Pclass', 'Spouse']).Survived.mean() # Having a spouse appears to increase survival in the 1st class only\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Split into training and test datasets, and build the model\n",
    "\n",
    "'''\n",
    "\n",
    "survived = d['Survived']\n",
    "del d['Survived']\n",
    "\n",
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now, split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(d,survived, random_state=1)\n",
    "\n",
    "# Create a decision tree classifier instance (start out with a small tree for interpretability)\n",
    "ctree = tree.DecisionTreeClassifier(random_state=1, max_depth=2)\n",
    "\n",
    "# Fit the decision tree classifier\n",
    "ctree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Create a feature vector\n",
    "features = d.columns.tolist()\n",
    "\n",
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How to interpret the diagram?\n",
    "ctree.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict what will happen for 1st class woman\n",
    "#features\n",
    "ctree.predict_proba([1, 1, 25, 0, 0, 0])\n",
    "ctree.predict([1, 1, 25, 0, 0, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Predict what will happen for a 3rd class man\n",
    "ctree.predict_proba([3, 0, 25, 0, 0, 0])\n",
    "ctree.predict([3, 0, 25, 0, 0, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "out = StringIO()\n",
    "tree.export_graphviz(ctree, out_file = out)\n",
    "# OUTPUT DOT LANGUAGE SCRIPTS\n",
    "print out.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(ctree, out_file='tree_vehicles.dot', feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import pydot\n",
    "# make sure pydot and graphviz are installed \n",
    "# if problems see here:\n",
    "# http://stackoverflow.com/questions/15951748/pydot-and-graphviz-error-couldnt-import-dot-parser-loading-of-dot-files-will/17902926#17902926\n",
    "\n",
    "dot_data = StringIO()  \n",
    "tree.export_graphviz(\n",
    "    ctree, \n",
    "    out_file=dot_data,\n",
    "    feature_names=features,  \n",
    "    class_names=[\"died\",\"survived\"],  \n",
    "    filled=True, \n",
    "    rounded=True,  \n",
    "    special_characters=True\n",
    ")  \n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Which features are the most important?\n",
    "ctree.feature_importances_\n",
    "\n",
    "# Clean up the output\n",
    "pd.DataFrame(zip(features, ctree.feature_importances_)).sort_index(by=1, ascending=False)\n",
    "\n",
    "# Make predictions on the test set\n",
    "preds = ctree.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "metrics.accuracy_score(y_test, preds)\n",
    "\n",
    "# Confusion matrix\n",
    "pd.crosstab(y_test, preds, rownames=['actual'], colnames=['predicted'])\n",
    "\n",
    "# Make predictions on the test set using predict_proba\n",
    "probs = ctree.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Calculate the AUC metric\n",
    "metrics.roc_auc_score(y_test, probs)\n",
    "\n",
    "# Decision Trees have notorouisly high variance, so what can we do\n",
    "# to better estimate the out of sample error of a high variance model?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "ctree = tree.DecisionTreeClassifier(random_state=1, max_depth=2)\n",
    "\n",
    "# compare AUC using cross-validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "cross_val_score(logreg, d, survived, cv=10, scoring='roc_auc').mean()\n",
    "cross_val_score(ctree, d, survived, cv=10, scoring='roc_auc').mean()\n",
    "\n",
    "\n",
    "# so far logistic regression is winning..\n",
    "\n",
    "'''\n",
    "\n",
    "FINE-TUNING THE TREE\n",
    "\n",
    "'''\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "# check CV score for max depth = 3\n",
    "ctree = tree.DecisionTreeClassifier(max_depth=3)\n",
    "np.mean(cross_val_score(ctree, d, survived, cv=5, scoring='roc_auc'))\n",
    "\n",
    "# check CV score for max depth = 10\n",
    "ctree = tree.DecisionTreeClassifier(max_depth=10)\n",
    "np.mean(cross_val_score(ctree, d, survived, cv=5, scoring='roc_auc'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Conduct a grid search for the best tree depth\n",
    "ctree = tree.DecisionTreeClassifier(random_state=1)\n",
    "depth_range = range(1, 20)\n",
    "param_grid = dict(max_depth=depth_range)\n",
    "grid = GridSearchCV(ctree, param_grid, cv=5, scoring='roc_auc')\n",
    "grid.fit(d, survived)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Check out the scores of the grid search\n",
    "grid_mean_scores = [result[1] for result in grid.grid_scores_]\n",
    "\n",
    "\n",
    "# Plot the results of the grid search\n",
    "plt.figure()\n",
    "plt.plot(depth_range, grid_mean_scores)\n",
    "plt.hold(True)\n",
    "plt.grid(True)\n",
    "plt.plot(grid.best_params_['max_depth'], grid.best_score_, 'ro', markersize=12, markeredgewidth=1.5,\n",
    "         markerfacecolor='None', markeredgecolor='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get the best estimator\n",
    "best = grid.best_estimator_\n",
    "\n",
    "cross_val_score(best, d, survived, cv=10, scoring='roc_auc').mean()\n",
    "cross_val_score(logreg, d, survived, cv=10, scoring='roc_auc').mean()\n",
    "\n",
    "\n",
    "# Still not as good as Logistic Regression.. \n",
    "# Let's try something else\n",
    "\n",
    "\n",
    "\n",
    "### EXERCISE ###\n",
    "''' Use Grid Search try scan over three parameters\n",
    "1. max_depth:     from 1 to 20\n",
    "2. criterion:     (either 'gini' or 'entropy')\n",
    "3. max_features : range (1,5)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Decision trees (like many other classification models)\n",
    "# can also be used for regression!\n",
    "\n",
    "\n",
    "drinks = pd.read_csv('../../data/drinks.csv', na_filter=False)\n",
    "\n",
    "drinks\n",
    "\n",
    "# Make dummy columns for each of the 6 regions\n",
    "for continent_ in ['AS', 'NA', 'EU', 'AF', 'SA', 'OC']:\n",
    "    drinks[continent_] = drinks['continent'] == continent_\n",
    "\n",
    "drinks\n",
    "\n",
    "\n",
    "del drinks['continent']\n",
    "del drinks['country']\n",
    "del drinks['total_litres_of_pure_alcohol'] # this doesn't seem fair does it?\n",
    "\n",
    "X = drinks.drop('wine_servings', axis=1)\n",
    "y = drinks['wine_servings']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)\n",
    "\n",
    "\n",
    "rtree = tree.DecisionTreeRegressor()\n",
    "\n",
    "rtree.fit(X_train, y_train)\n",
    "rtree.predict(X_test)\n",
    "\n",
    "scores = cross_val_score(rtree, X, y, cv=10, scoring='mean_squared_error')\n",
    "mse_scores = -scores\n",
    "mse_scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores\n",
    "rmse_scores.mean()\n",
    "\n",
    "wine_mean = y.mean()\n",
    "wine_mean\n",
    "\n",
    "features = X.columns\n",
    "pd.DataFrame(zip(features, rtree.feature_importances_)).sort_index(by=1, ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
