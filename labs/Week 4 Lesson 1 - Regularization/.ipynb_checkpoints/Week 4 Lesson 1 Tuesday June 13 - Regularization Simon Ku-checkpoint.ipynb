{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab - Regularization\n",
    "\n",
    "## Week 4 Tuesday 11th June\n",
    "\n",
    "### TASK: Regularized regression\n",
    "### FUNCTIONS: Ridge, RidgeCV, Lasso, LassoCV\n",
    "### DOCUMENTATION: http://scikit-learn.org/stable/modules/linear_model.html\n",
    "### DATA: Crime (n=319 non-null, p=122, type=regression)\n",
    "### DATA DICTIONARY: http://archive.ics.uci.edu/ml/datasets/Communities+and+Crime\n",
    "\n",
    "This data set contains data on violent crimes within a community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########## Prepare data ##########\n",
    "# read in data, remove categorical features, remove rows with missing values\n",
    "import pandas as pd\n",
    "crime = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data', header=None, na_values=['?'])\n",
    "crime = crime.iloc[:, 5:]\n",
    "crime.dropna(inplace=True)\n",
    "crime.head()\n",
    "\n",
    "# define X and y\n",
    "X = crime.iloc[:, :-1]\n",
    "y = crime.iloc[:, -1]\n",
    "\n",
    "# split into train/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319, 122)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many columns are in X?\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -3.66188167e+00,   6.98124465e-01,  -2.61955467e-01,\n",
       "        -2.85270027e-01,  -1.64740837e-01,   2.46972333e-01,\n",
       "        -1.09290051e+00,  -5.96857796e-01,   1.11200239e+00,\n",
       "        -7.21968931e-01,   4.27346598e+00,  -2.28040268e-01,\n",
       "         8.04875769e-01,  -2.57934732e-01,  -2.63458023e-01,\n",
       "        -1.04616958e+00,   6.07784197e-01,   7.73552561e-01,\n",
       "         5.96468029e-02,   6.90215922e-01,   2.16759430e-02,\n",
       "        -4.87802949e-01,  -5.18858404e-01,   1.39478815e-01,\n",
       "        -1.24417942e-01,   3.15003821e-01,  -1.52633736e-01,\n",
       "        -9.65003927e-01,   1.17142163e+00,  -3.08546690e-02,\n",
       "        -9.29085548e-01,   1.24654586e-01,   1.98104506e-01,\n",
       "         7.30804821e-01,  -1.77337294e-01,   8.32927588e-02,\n",
       "         3.46045601e-01,   5.01837338e-01,   1.57062958e+00,\n",
       "        -4.13478807e-01,   1.39350802e+00,  -3.49428114e+00,\n",
       "         7.09577818e-01,  -8.32141352e-01,  -1.39984927e+00,\n",
       "         1.02482840e+00,   2.13855006e-01,  -6.18937325e-01,\n",
       "         5.28954490e-01,   7.98294890e-02,   5.93688560e-02,\n",
       "        -1.68582667e-01,   7.31264051e-01,  -1.39635208e+00,\n",
       "         2.38507704e-01,   5.50621439e-01,  -5.61447867e-01,\n",
       "         6.18989764e-01,   2.55517024e+00,  -3.71769599e+00,\n",
       "         7.09191935e-01,   3.82041439e-01,   8.23752836e-01,\n",
       "        -1.67703547e+00,  -1.73150450e+00,   9.90120171e-01,\n",
       "        -5.72745697e-01,  -1.45877295e+00,   8.68032144e-01,\n",
       "         5.15959984e-01,   3.14453207e-02,   2.01869791e-01,\n",
       "         9.65291940e-02,   2.13034099e+00,  -6.95374423e-02,\n",
       "         4.62477023e-02,  -1.10565955e-02,  -1.34313780e-02,\n",
       "        -1.04515494e-01,  -8.76985171e-01,   4.26781907e-01,\n",
       "        -1.85405795e-01,  -8.16215517e-01,  -2.86596076e-01,\n",
       "        -1.56110708e-01,   1.76468580e+00,  -5.70163730e-01,\n",
       "        -7.54066704e-02,  -1.74212697e-01,  -8.89747220e-02,\n",
       "         2.26336403e-01,   1.38030073e+00,  -3.37304744e-01,\n",
       "        -2.57856611e-02,   8.91299188e-02,   3.49876793e-01,\n",
       "        -1.22428557e+00,  -3.67941205e+01,  -6.95699750e-01,\n",
       "         2.95269279e-01,  -1.48590316e-03,   2.34206416e-01,\n",
       "        -7.09533984e-03,   3.67152957e+01,  -8.90665109e-02,\n",
       "         3.79550678e-02,   3.19375782e-01,   4.60708905e-01,\n",
       "         1.41090069e-01,  -6.67017320e-01,  -2.59035245e-01,\n",
       "        -4.60600755e-04,  -1.51868232e-02,   7.54768410e-02,\n",
       "        -2.36105498e-03,  -1.50328233e-01,   1.85575558e-01,\n",
       "         6.31979224e-01,  -1.50253625e-01,   1.87638817e-02,\n",
       "        -3.38095851e-02,  -4.46104032e-01])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## Linear Regression Model Without Regularization ##########\n",
    "# linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "lm.coef_\n",
    "# What are these numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (no regularization) = 0.233813676495\n"
     ]
    }
   ],
   "source": [
    "# make predictions and evaluate\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "preds = lm.predict(X_test)\n",
    "print('RMSE (no regularization) =', np.sqrt(metrics.mean_squared_error(y_test, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4.00298418e-03,   3.51647445e-02,   6.03535935e-02,\n",
       "        -7.68532502e-02,  -1.76099849e-02,   4.53791433e-02,\n",
       "         8.81586468e-03,  -2.88885814e-02,  -1.92143587e-02,\n",
       "         3.36122201e-02,   5.71590736e-04,  -4.85438136e-02,\n",
       "         5.55725157e-02,  -1.15934270e-01,  -1.11880845e-01,\n",
       "        -3.32742094e-01,  -1.12302031e-02,   9.63833243e-02,\n",
       "        -8.92057732e-02,   8.42691702e-02,  -1.67246717e-02,\n",
       "         7.42520308e-03,  -1.21294025e-01,  -6.70155789e-02,\n",
       "        -1.74250249e-03,   1.69446833e-01,   3.18217654e-02,\n",
       "        -1.00209834e-01,   3.97535644e-02,  -1.19173054e-01,\n",
       "        -1.04445267e-01,  -5.14946676e-03,   1.10071013e-01,\n",
       "        -3.22958955e-02,  -1.40601627e-01,   7.72658029e-02,\n",
       "         9.07962536e-02,  -3.78878862e-03,   4.61941793e-02,\n",
       "         6.30299731e-02,  -3.09236932e-02,   1.02883578e-02,\n",
       "         9.70425568e-02,  -1.28936944e-01,  -1.38268907e-01,\n",
       "        -6.37169778e-02,  -8.80160419e-02,  -4.01991014e-02,\n",
       "         8.11064596e-02,  -6.30663975e-02,   1.29756859e-01,\n",
       "        -6.25210624e-02,   1.60531213e-02,  -1.39061824e-01,\n",
       "         6.39822353e-02,   4.87118744e-02,  -7.68217532e-03,\n",
       "        -1.53523412e-03,   1.73028280e-02,  -1.37258659e-03,\n",
       "        -1.97381922e-02,   4.47492477e-02,   3.53941624e-03,\n",
       "        -1.64126843e-02,  -1.62363185e-02,   7.10860268e-02,\n",
       "        -1.34543849e-01,   3.03401863e-02,   2.87012058e-02,\n",
       "         2.62507811e-01,   3.87946361e-02,   4.16976393e-02,\n",
       "         2.45959130e-02,   4.02803695e-02,  -1.15568319e-02,\n",
       "         1.82352709e-02,  -1.11769965e-04,   1.17220288e-02,\n",
       "        -3.27960499e-02,  -2.06336390e-02,  -2.01424775e-02,\n",
       "        -1.55746075e-02,  -1.50471159e-01,   5.00237268e-02,\n",
       "         1.67270388e-02,   1.27989507e-01,  -7.55437715e-02,\n",
       "        -7.22756020e-02,  -8.80283128e-02,   6.42301728e-02,\n",
       "         1.39781081e-01,   4.71861289e-02,  -6.42667056e-02,\n",
       "         3.16227166e-02,  -1.36066226e-02,   5.16507328e-02,\n",
       "        -4.60206271e-02,   6.55072592e-04,   3.51488294e-02,\n",
       "        -1.68717518e-02,  -7.00033520e-03,   4.99335627e-02,\n",
       "         8.40464679e-02,   3.87553978e-03,  -1.23632746e-01,\n",
       "        -2.24505480e-02,  -2.47960018e-03,   4.13468551e-02,\n",
       "         8.26295505e-02,  -4.84167513e-02,   8.21329530e-03,\n",
       "         1.57843967e-02,  -1.94698620e-02,   4.09120489e-02,\n",
       "        -4.42911592e-02,  -5.64373896e-02,   1.17841094e-01,\n",
       "         7.34994342e-02,  -2.78153968e-02,   3.74136314e-02,\n",
       "        -7.67878399e-02,  -4.65440973e-02])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## Ridge Regression Model ##########\n",
    "# ridge regression (alpha must be positive, larger means more regularization)\n",
    "from sklearn.linear_model import Ridge\n",
    "rreg = Ridge(alpha=0.1, normalize=True)\n",
    "rreg.fit(X_train, y_train)\n",
    "rreg.coef_\n",
    "#preds = rreg.predict(X_test)\n",
    "#print('RMSE (Ridge reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds)))\n",
    "# Is this model better? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Ridge reg.) = 0.164279068049\n"
     ]
    }
   ],
   "source": [
    "preds = rreg.predict(X_test)\n",
    "print('RMSE (Ridge reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds)))\n",
    "# Is this model better? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Alpha Value:  1.0\n",
      "RMSE (Ridge CV reg.) = 0.163129782343\n"
     ]
    }
   ],
   "source": [
    "# use RidgeCV to select best alpha\n",
    "from sklearn.linear_model import RidgeCV\n",
    "alpha_range = 10.**np.arange(-2, 3)\n",
    "rregcv = RidgeCV(normalize=True, scoring='neg_mean_squared_error', alphas=alpha_range)\n",
    "rregcv.fit(X_train, y_train)\n",
    "\n",
    "# Print the optimal value of Alpha for Ridge Regression\n",
    "print('Optimal Alpha Value: ', rregcv.alpha_)\n",
    "\n",
    "# Print the RMSE for the ridge regression model\n",
    "preds = rregcv.predict(X_test)\n",
    "print ('RMSE (Ridge CV reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds)))\n",
    "# What is the range of alpha values we are searching over?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.35479199e-03,   3.66493623e-03,   5.67246153e-02,\n",
       "        -6.65596102e-02,   7.50154730e-03,   3.73570277e-03,\n",
       "         1.48458510e-02,  -8.26212596e-03,  -9.14751985e-04,\n",
       "         8.17782143e-03,  -9.58221848e-04,   3.99333039e-03,\n",
       "        -2.04774531e-02,  -3.80310378e-02,  -7.06311041e-02,\n",
       "        -9.07995340e-02,   3.92365601e-03,   3.68491166e-02,\n",
       "        -2.35269424e-02,  -1.36618143e-02,  -9.83437557e-03,\n",
       "         1.30086791e-02,  -3.43297706e-02,  -5.04638755e-02,\n",
       "        -9.82883411e-04,   7.47392898e-02,   2.63572032e-02,\n",
       "        -1.07987605e-02,   3.16035521e-02,  -2.17283831e-02,\n",
       "        -4.45588182e-03,  -1.06490401e-02,   4.42829964e-02,\n",
       "        -3.72944143e-02,  -6.18713730e-02,   3.20124805e-02,\n",
       "         5.85549588e-03,  -1.23569409e-02,   6.53560040e-02,\n",
       "         3.46461301e-02,   6.00524147e-02,   6.39805254e-02,\n",
       "         2.58651194e-02,  -6.73126020e-02,  -7.02669216e-02,\n",
       "        -5.05555985e-02,  -6.41318316e-02,   8.24959798e-03,\n",
       "         9.27945661e-03,   2.77399795e-03,   5.26650167e-02,\n",
       "        -3.83854430e-03,  -6.04984296e-03,  -1.53114959e-02,\n",
       "         1.72393078e-02,   2.11864055e-02,   4.40697120e-04,\n",
       "         3.32044620e-03,   7.16243927e-03,   6.66440446e-03,\n",
       "        -7.72185920e-05,   2.69852368e-03,   2.81341584e-02,\n",
       "         1.97363420e-02,  -6.50713075e-03,   1.32688080e-02,\n",
       "        -1.33248499e-02,  -1.46491869e-02,   2.30579186e-02,\n",
       "         7.96862124e-02,   2.12388813e-04,   1.34268743e-02,\n",
       "        -2.66304497e-02,  -1.32590800e-02,   2.00181039e-02,\n",
       "         7.27144905e-03,   5.04718226e-03,   2.88522636e-02,\n",
       "         7.53947389e-03,  -7.97163573e-03,  -5.55521252e-03,\n",
       "        -1.71984008e-03,  -3.34721090e-02,  -8.08297495e-03,\n",
       "        -8.41053916e-03,   3.05921418e-04,   9.38632965e-03,\n",
       "        -6.90899365e-03,  -3.05496999e-02,   3.77828928e-02,\n",
       "         6.33462868e-02,   1.10005833e-02,  -2.29792767e-02,\n",
       "         7.97147365e-03,   7.50701811e-03,   8.23752156e-03,\n",
       "         4.59206678e-05,   1.14778395e-03,   2.78344743e-05,\n",
       "        -2.12672814e-03,   1.25110687e-02,   3.42230959e-02,\n",
       "         4.08143239e-02,   1.42423735e-03,  -8.29660922e-02,\n",
       "        -3.52386599e-02,   3.32237250e-02,  -1.77830301e-03,\n",
       "         4.04432608e-02,   1.85584939e-02,   1.16761082e-02,\n",
       "         8.52151434e-03,  -1.32322008e-02,   1.22894191e-02,\n",
       "        -6.44216624e-03,  -5.02763328e-03,   3.37623134e-02,\n",
       "         2.17114525e-02,  -8.21584473e-03,   2.04175614e-02,\n",
       "        -3.06703463e-02,  -9.00275805e-04])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rregcv.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Alpha Value:  1.0\n",
      "RMSE (Ridge CV reg.) = 0.163129782343\n"
     ]
    }
   ],
   "source": [
    "# use RidgeCV to select best alpha\n",
    "from sklearn.linear_model import RidgeCV\n",
    "alpha_range = 10.**np.arange(-2, 3)\n",
    "rregcv = RidgeCV(normalize=True,  alphas=alpha_range)\n",
    "rregcv.fit(X_train, y_train)\n",
    "\n",
    "# Print the optimal value of Alpha for Ridge Regression\n",
    "print('Optimal Alpha Value: ', rregcv.alpha_)\n",
    "\n",
    "# Print the RMSE for the ridge regression model\n",
    "preds = rregcv.predict(X_test)\n",
    "print ('RMSE (Ridge CV reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds)))\n",
    "# What is the range of alpha values we are searching over?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        , -0.03974695,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.        , -0.27503063,\n",
       "       -0.        , -0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -0.        ,\n",
       "       -0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "       -0.        ,  0.        ])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## Lasso Regression Model ##########\n",
    "# lasso (alpha must be positive, larger means more regularization)\n",
    "from sklearn.linear_model import Lasso\n",
    "las = Lasso(alpha=0.01, normalize=True)\n",
    "las.fit(X_train, y_train)\n",
    "las.coef_\n",
    "#preds = las.predict(X_test)\n",
    "#print('RMSE (Lasso reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Lasso reg.) = 0.198165225429\n"
     ]
    }
   ],
   "source": [
    "preds = las.predict(X_test)\n",
    "print('RMSE (Lasso reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Lasso reg.) = 0.164502413721\n"
     ]
    }
   ],
   "source": [
    "# try a smaller alpha\n",
    "las = Lasso(alpha=0.0001, normalize=True)\n",
    "las.fit(X_train, y_train)\n",
    "las.coef_\n",
    "preds = las.predict(X_test)\n",
    "print('RMSE (Lasso reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Alpha Value:  0.001\n",
      "RMSE (Lasso CV reg.) = 0.160039024044\n"
     ]
    }
   ],
   "source": [
    "# use LassoCV to select best alpha (tries 100 alphas by default)\n",
    "from sklearn.linear_model import LassoCV\n",
    "alpha_range = 10.**np.arange(-10, 10)\n",
    "lascv = LassoCV(normalize=True, alphas=alpha_range)\n",
    "lascv.fit(X_train, y_train)\n",
    "print('Optimal Alpha Value: ',lascv.alpha_)\n",
    "lascv.coef_\n",
    "preds = lascv.predict(X_test)\n",
    "print('RMSE (Lasso CV reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Carry out Elastic net regularised regression\n",
    "\n",
    "### Lookup [Elastic Net](http://scikit-learn.org/stable/modules/linear_model.html#elastic-net) and complete the following.\n",
    "\n",
    "\n",
    "\n",
    "1. What is elastic net?\n",
    "2. How does it work?\n",
    "3. Run elastic net on the above dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.        ,  0.08672231, -0.22257432,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        ,  0.        ,  0.05102937, -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.0700438 ,  0.        ,\n",
       "        0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.03387024,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.04775612, -0.14505711,\n",
       "       -0.03623363, -0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.15742425,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        ,  0.        ,  0.        , -0.        ,\n",
       "       -0.        ,  0.        , -0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.04156342, -0.        , -0.        ,  0.00067274,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        ,  0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.11619895,  0.        , -0.        , -0.        ,  0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -0.        ,\n",
       "       -0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        ,  0.01830395,\n",
       "       -0.        ,  0.        ])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup the elastic net model\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "alpha_range = 10.**np.arange(-2, 3)\n",
    "enetcv = ElasticNetCV(alphas=alpha_range, l1_ratio=0.7)\n",
    "\n",
    "enetcv.fit(X_train, y_train)\n",
    "enetcv.coef_\n",
    "#preds = enet.predict(X_test)\n",
    "#print('RMSE (ENET CV reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       5     6     7     8     9     10    11    12    13    14   ...    117  \\\n",
      "185   0.28  0.33  0.66  0.45  0.09  0.02  0.51  0.60  0.48  0.37  ...   0.05   \n",
      "637   0.13  0.53  0.25  0.70  0.10  0.12  0.42  0.53  0.35  0.38  ...   0.08   \n",
      "447   0.08  0.49  1.00  0.00  0.13  0.19  0.45  0.55  0.35  0.28  ...   0.11   \n",
      "1859  0.12  0.44  0.36  0.64  0.03  0.15  0.39  0.48  0.28  0.41  ...   0.26   \n",
      "1050  0.29  0.34  0.08  0.86  0.24  0.04  0.63  0.78  0.71  0.27  ...   0.44   \n",
      "1872  0.11  0.42  0.81  0.35  0.05  0.01  0.57  0.65  0.55  0.41  ...   0.03   \n",
      "81    0.09  0.43  0.05  0.81  0.11  0.22  0.47  0.54  0.38  0.47  ...   0.48   \n",
      "674   0.14  0.28  0.47  0.61  0.04  0.01  0.32  0.44  0.28  0.55  ...   0.22   \n",
      "1595  0.14  0.56  0.85  0.29  0.09  0.03  0.76  0.83  0.77  0.37  ...   0.17   \n",
      "1835  0.21  0.73  0.70  0.10  0.09  0.76  0.52  0.60  0.41  0.29  ...   0.18   \n",
      "205   0.16  0.32  0.02  0.90  0.21  0.05  0.56  0.61  0.53  0.39  ...   0.24   \n",
      "1313  1.00  0.44  0.10  0.72  0.10  0.37  0.41  0.53  0.33  0.30  ...   0.35   \n",
      "1685  0.04  0.58  0.01  0.83  0.13  0.21  0.44  0.49  0.29  0.25  ...   0.11   \n",
      "1534  0.21  0.73  0.03  0.50  1.00  0.43  0.43  0.57  0.37  0.26  ...   0.58   \n",
      "1957  0.27  0.32  0.66  0.46  0.05  0.01  0.39  0.51  0.32  0.39  ...   0.00   \n",
      "33    0.09  0.43  0.51  0.58  0.04  0.01  0.58  0.56  0.50  0.52  ...   0.10   \n",
      "711   0.10  0.41  0.34  0.72  0.03  0.01  0.50  0.52  0.40  0.49  ...   0.14   \n",
      "177   0.35  0.50  0.58  0.21  0.70  0.45  0.41  0.57  0.36  0.35  ...   0.17   \n",
      "1838  0.70  0.35  0.31  0.62  0.14  0.09  0.38  0.49  0.30  0.37  ...   0.09   \n",
      "1686  0.14  0.39  0.15  0.84  0.06  0.06  0.42  0.50  0.33  0.40  ...   0.29   \n",
      "698   0.18  0.54  0.02  0.76  0.09  0.53  0.47  0.56  0.36  0.22  ...   0.06   \n",
      "365   0.15  0.36  0.41  0.64  0.05  0.06  0.36  0.46  0.28  0.55  ...   0.35   \n",
      "1263  0.12  0.31  0.07  0.68  0.82  0.29  0.24  0.41  0.23  0.53  ...   0.38   \n",
      "1159  0.58  0.40  0.86  0.00  0.91  0.26  0.36  0.48  0.31  0.37  ...   0.42   \n",
      "597   0.07  0.43  0.04  0.93  0.05  0.10  0.33  0.51  0.29  0.43  ...   0.16   \n",
      "572   0.11  0.41  0.05  0.93  0.11  0.04  0.29  0.41  0.27  0.63  ...   0.67   \n",
      "158   0.14  0.22  0.17  0.84  0.06  0.05  0.26  0.33  0.21  0.84  ...   0.65   \n",
      "1265  0.10  0.40  0.39  0.65  0.03  0.07  0.44  0.48  0.32  0.41  ...   0.27   \n",
      "919   0.19  0.23  0.01  0.94  0.07  0.09  0.26  0.39  0.23  0.54  ...   0.38   \n",
      "973   0.06  0.66  1.00  0.00  0.06  0.28  0.42  0.55  0.36  0.29  ...   0.21   \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
      "641   0.21  0.47  0.76  0.08  0.09  0.59  0.55  0.68  0.50  0.29  ...   1.00   \n",
      "1847  0.43  0.62  1.00  0.00  0.07  0.48  0.54  0.62  0.42  0.28  ...   0.66   \n",
      "1341  0.40  0.41  0.22  0.67  0.22  0.23  0.34  0.48  0.29  0.33  ...   0.12   \n",
      "1643  0.11  0.40  0.03  0.93  0.12  0.05  0.33  0.52  0.30  0.31  ...   0.41   \n",
      "1271  0.13  0.48  0.12  0.63  0.04  0.58  0.45  0.49  0.31  0.31  ...   0.10   \n",
      "16    0.15  0.31  0.40  0.63  0.14  0.06  0.58  0.72  0.65  0.47  ...   0.22   \n",
      "103   0.24  0.40  0.12  0.74  0.11  0.27  0.41  0.47  0.29  0.38  ...   0.00   \n",
      "50    0.06  0.31  0.17  0.84  0.04  0.03  0.40  0.48  0.29  0.43  ...   0.16   \n",
      "793   0.09  0.37  0.12  0.86  0.11  0.15  0.35  0.42  0.26  0.47  ...   0.12   \n",
      "499   0.25  0.62  0.31  0.40  0.24  0.64  0.45  0.57  0.37  0.30  ...   0.24   \n",
      "1510  0.16  0.43  0.03  0.87  0.15  0.11  0.38  0.48  0.32  0.46  ...   0.34   \n",
      "1333  0.22  0.49  0.06  0.77  0.13  0.29  0.50  0.56  0.37  0.22  ...   0.79   \n",
      "366   0.16  0.40  0.23  0.79  0.03  0.04  0.46  0.52  0.38  0.53  ...   0.06   \n",
      "250   0.62  0.35  0.62  0.48  0.11  0.02  0.37  0.53  0.32  0.30  ...   0.06   \n",
      "916   0.08  0.36  0.04  0.91  0.17  0.06  0.30  0.33  0.23  0.71  ...   1.00   \n",
      "1567  0.10  0.55  0.35  0.66  0.10  0.18  0.47  0.54  0.33  0.18  ...   0.42   \n",
      "1587  0.06  0.36  0.11  0.90  0.04  0.01  0.52  0.56  0.48  0.51  ...   0.09   \n",
      "1724  0.14  0.40  0.03  0.76  0.40  0.37  0.33  0.65  0.41  0.24  ...   0.04   \n",
      "1069  0.24  0.31  0.03  0.81  0.29  0.18  0.40  0.56  0.38  0.46  ...   0.09   \n",
      "1749  0.05  0.32  0.46  0.62  0.04  0.04  0.35  0.39  0.26  0.70  ...   0.39   \n",
      "1491  0.16  0.62  0.03  0.74  0.48  0.42  0.44  0.57  0.40  0.25  ...   0.38   \n",
      "396   0.14  1.00  0.00  0.77  0.02  1.00  0.72  0.65  0.45  0.26  ...   0.67   \n",
      "727   0.16  0.41  1.00  0.19  0.02  0.01  0.47  0.52  0.36  0.48  ...   0.11   \n",
      "840   0.15  0.53  0.11  0.81  0.16  0.16  0.42  0.54  0.29  0.13  ...   0.02   \n",
      "740   0.16  0.15  0.43  0.53  0.26  0.18  0.16  0.58  0.30  0.30  ...   0.57   \n",
      "1246  0.09  0.34  0.24  0.80  0.04  0.01  0.39  0.41  0.26  0.51  ...   0.45   \n",
      "1594  0.06  0.49  0.27  0.69  0.09  0.19  0.35  0.42  0.26  0.67  ...   0.17   \n",
      "401   0.99  0.42  0.59  0.44  0.11  0.11  0.44  0.56  0.37  0.39  ...   0.57   \n",
      "1481  0.96  0.44  1.00  0.14  0.05  0.01  0.45  0.53  0.36  0.39  ...   0.48   \n",
      "175   0.13  0.51  0.13  0.80  0.34  0.10  0.27  0.45  0.25  0.44  ...   0.02   \n",
      "\n",
      "       118   119   120   121   122   123  124   125   126  \n",
      "185   0.23  0.19  0.09  0.10  0.04  0.00  1.0  0.33  0.09  \n",
      "637   0.06  0.36  0.31  0.03  0.03  0.67  0.0  0.34  0.15  \n",
      "447   0.01  1.00  1.00  0.04  0.03  0.74  0.0  0.19  0.21  \n",
      "1859  0.04  0.46  0.19  0.03  0.03  0.69  0.5  0.61  0.19  \n",
      "1050  0.17  0.28  0.43  0.10  0.08  0.46  1.0  0.72  0.18  \n",
      "1872  0.12  0.15  0.33  0.17  0.03  0.92  0.0  0.25  0.19  \n",
      "81    0.07  0.20  0.16  0.10  0.01  0.80  1.0  0.00  0.10  \n",
      "674   0.12  0.19  0.17  0.08  0.02  0.82  0.0  0.60  0.12  \n",
      "1595  0.34  0.07  0.27  0.26  0.04  0.56  0.5  1.00  0.19  \n",
      "1835  0.02  1.00  0.59  0.10  0.04  0.75  0.0  1.00  0.13  \n",
      "205   0.11  0.25  0.20  0.06  0.04  0.93  1.0  1.00  0.14  \n",
      "1313  1.00  0.20  0.18  1.00  0.47  0.87  0.5  0.26  0.17  \n",
      "1685  0.05  0.16  0.20  0.06  0.04  0.22  0.5  0.59  0.48  \n",
      "1534  0.05  0.67  0.17  0.05  0.05  0.78  0.5  0.37  0.15  \n",
      "1957  0.30  0.14  0.08  0.09  0.02  0.39  0.0  0.41  0.05  \n",
      "33    0.14  0.11  0.19  0.05  0.01  0.75  0.0  0.60  0.10  \n",
      "711   0.05  0.30  0.06  0.03  0.01  0.84  0.0  0.61  0.10  \n",
      "177   0.04  1.00  1.00  0.29  0.19  0.49  0.0  0.55  0.36  \n",
      "1838  1.00  0.06  0.05  0.68  0.15  0.70  0.5  0.36  0.12  \n",
      "1686  0.18  0.13  0.06  0.05  0.02  0.69  1.0  0.43  0.11  \n",
      "698   0.13  0.23  0.02  0.15  0.02  0.79  1.0  0.73  0.07  \n",
      "365   0.10  0.24  0.20  0.11  0.03  0.70  0.5  1.00  0.12  \n",
      "1263  0.03  0.59  0.38  0.04  0.03  0.75  1.0  0.56  0.15  \n",
      "1159  0.16  0.56  1.00  0.26  0.28  0.66  1.0  0.38  0.31  \n",
      "597   0.09  0.13  0.14  0.00  0.01  0.56  0.0  0.45  0.12  \n",
      "572   0.08  0.22  0.15  0.07  0.01  0.62  0.0  0.00  0.10  \n",
      "158   0.07  0.33  0.09  0.16  0.04  0.82  1.0  0.37  0.20  \n",
      "1265  0.15  0.11  0.01  0.05  0.02  0.58  1.0  0.56  0.12  \n",
      "919   0.54  0.06  0.06  0.10  0.04  0.91  1.0  0.53  0.12  \n",
      "973   0.02  0.64  0.40  0.03  0.02  0.80  0.0  0.65  0.25  \n",
      "...    ...   ...   ...   ...   ...   ...  ...   ...   ...  \n",
      "641   0.05  0.68  0.97  0.15  0.08  0.79  1.0  1.00  0.29  \n",
      "1847  0.07  0.97  1.00  0.02  0.03  0.80  0.0  0.00  0.05  \n",
      "1341  0.24  0.26  0.16  0.41  0.36  0.28  0.5  0.27  0.20  \n",
      "1643  0.09  0.21  0.06  0.02  0.03  0.69  1.0  0.52  0.16  \n",
      "1271  0.10  0.21  0.00  0.07  0.02  0.62  1.0  0.36  0.11  \n",
      "16    0.06  0.39  0.84  0.06  0.06  0.91  0.5  0.88  0.26  \n",
      "103   0.25  0.15  0.05  0.11  0.03  0.76  1.0  1.00  0.08  \n",
      "50    0.04  0.26  0.01  0.03  0.01  0.84  0.5  0.82  0.11  \n",
      "793   0.06  0.26  0.05  0.09  0.02  0.88  0.5  0.86  0.16  \n",
      "499   0.16  0.25  0.10  0.58  0.34  0.10  0.5  0.40  0.82  \n",
      "1510  0.12  0.22  0.14  0.05  0.03  0.49  0.0  1.00  0.11  \n",
      "1333  0.15  0.24  0.09  0.08  0.04  0.84  0.5  1.00  0.09  \n",
      "366   0.06  0.41  0.21  0.06  0.01  0.76  0.0  0.43  0.06  \n",
      "250   0.51  0.19  0.25  0.15  0.02  0.81  0.0  0.71  0.00  \n",
      "916   0.06  0.23  0.24  0.01  0.03  0.94  1.0  0.42  0.24  \n",
      "1567  0.04  0.40  0.12  0.11  0.00  0.74  0.0  0.53  0.04  \n",
      "1587  0.09  0.13  0.05  0.09  0.01  0.63  0.0  0.00  0.12  \n",
      "1724  0.04  0.52  0.17  0.04  0.03  0.80  0.5  0.66  0.14  \n",
      "1069  0.32  0.12  0.32  0.29  0.09  0.81  0.5  0.70  0.22  \n",
      "1749  0.08  0.12  0.01  0.10  0.02  0.92  0.0  0.86  0.17  \n",
      "1491  0.07  0.40  0.14  0.07  0.05  0.85  0.5  0.61  0.19  \n",
      "396   0.08  0.30  0.13  0.05  0.02  0.89  0.0  0.50  0.07  \n",
      "727   0.14  0.19  0.15  0.24  0.03  0.71  1.0  0.71  0.12  \n",
      "840   0.12  0.20  0.07  0.12  0.02  0.68  0.0  0.58  0.09  \n",
      "740   0.04  0.61  1.00  0.13  0.07  0.71  0.0  1.00  0.27  \n",
      "1246  0.17  0.09  0.08  0.02  0.01  0.74  1.0  0.45  0.10  \n",
      "1594  0.07  0.15  0.22  0.02  0.02  0.78  1.0  0.66  0.23  \n",
      "401   0.28  0.55  0.62  0.37  0.38  0.57  0.5  0.24  0.25  \n",
      "1481  0.75  0.20  0.26  0.64  0.24  0.01  0.5  0.89  0.15  \n",
      "175   0.07  0.34  0.39  0.02  0.02  0.84  0.0  0.36  0.10  \n",
      "\n",
      "[239 rows x 122 columns]\n"
     ]
    }
   ],
   "source": [
    "print (X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       5     6     7     8     9     10    11    12    13    14   ...    117  \\\n",
      "693   0.06  0.29  1.00  0.13  0.04  0.01  0.38  0.49  0.33  0.62  ...   0.12   \n",
      "630   0.17  0.54  1.00  0.00  0.01  0.10  0.55  0.50  0.33  0.37  ...   0.21   \n",
      "464   0.27  0.29  0.04  0.90  0.13  0.04  0.39  0.47  0.32  0.52  ...   0.35   \n",
      "738   0.09  0.24  0.02  0.95  0.10  0.01  0.32  0.57  0.38  0.46  ...   0.09   \n",
      "739   0.19  0.57  0.08  0.83  0.25  0.11  0.44  0.48  0.26  0.06  ...   0.07   \n",
      "1536  0.30  0.42  0.87  0.30  0.03  0.02  0.45  0.47  0.30  0.43  ...   0.34   \n",
      "1345  0.10  0.49  0.09  0.80  0.41  0.08  0.40  0.40  0.22  0.22  ...   0.19   \n",
      "496   0.11  0.39  0.30  0.69  0.10  0.17  0.26  0.46  0.26  0.40  ...   0.02   \n",
      "1008  0.03  0.37  0.16  0.83  0.09  0.05  0.50  0.65  0.52  0.41  ...   0.44   \n",
      "1711  0.20  0.28  0.06  0.79  0.30  0.20  0.34  0.52  0.36  0.38  ...   0.44   \n",
      "525   0.60  0.36  0.06  0.67  0.10  0.64  0.39  0.51  0.32  0.35  ...   0.32   \n",
      "1420  0.08  0.39  0.14  0.88  0.02  0.01  0.39  0.47  0.29  0.46  ...   0.32   \n",
      "305   0.04  0.20  0.03  0.87  0.33  0.10  0.30  0.35  0.22  0.67  ...   0.19   \n",
      "505   0.25  0.29  0.31  0.74  0.06  0.01  0.51  0.63  0.52  0.50  ...   0.11   \n",
      "1773  0.06  0.35  0.62  0.43  0.15  0.46  0.31  0.47  0.27  0.47  ...   0.65   \n",
      "1477  0.21  0.94  0.10  0.37  0.53  1.00  0.52  0.62  0.42  0.23  ...   0.52   \n",
      "867   0.07  0.22  0.32  0.73  0.04  0.09  0.27  0.37  0.25  0.82  ...   0.06   \n",
      "513   0.17  0.35  0.03  0.84  0.21  0.17  0.36  0.42  0.28  0.53  ...   0.74   \n",
      "532   0.52  0.38  0.38  0.65  0.06  0.07  0.45  0.53  0.37  0.44  ...   0.23   \n",
      "783   0.08  0.48  1.00  0.17  0.03  0.01  0.52  0.51  0.37  0.48  ...   0.19   \n",
      "1060  1.00  0.69  0.09  0.43  1.00  0.49  0.43  0.57  0.36  0.20  ...   1.00   \n",
      "1839  0.06  0.35  0.16  0.80  0.13  0.11  0.29  0.48  0.29  0.52  ...   0.16   \n",
      "1633  0.51  0.31  0.60  0.46  0.06  0.09  0.42  0.54  0.39  0.48  ...   0.07   \n",
      "553   0.16  0.40  0.35  0.64  0.16  0.18  0.26  0.46  0.26  0.42  ...   0.17   \n",
      "408   0.06  0.41  0.97  0.23  0.02  0.01  0.44  0.47  0.29  0.42  ...   0.10   \n",
      "1542  0.17  0.51  0.04  0.62  0.75  0.39  0.45  0.61  0.45  0.31  ...   0.45   \n",
      "95    0.07  0.34  0.08  0.84  0.32  0.05  0.28  0.53  0.32  0.49  ...   0.33   \n",
      "1626  0.11  0.36  0.15  0.72  0.11  0.30  0.39  0.57  0.40  0.56  ...   0.38   \n",
      "68    0.05  0.59  0.23  0.39  0.09  1.00  0.45  0.55  0.37  0.45  ...   0.31   \n",
      "1303  0.12  0.81  0.01  0.56  0.04  1.00  0.63  0.59  0.40  0.32  ...   0.47   \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
      "1907  0.42  0.30  0.58  0.53  0.04  0.01  0.38  0.47  0.30  0.54  ...   0.23   \n",
      "1710  0.18  1.00  0.00  0.56  0.02  1.00  0.67  0.65  0.45  0.23  ...   0.42   \n",
      "1566  0.28  0.46  0.17  0.66  0.09  0.42  0.60  0.70  0.58  0.30  ...   0.25   \n",
      "874   0.05  0.21  0.40  0.64  0.11  0.06  0.34  0.73  0.48  0.31  ...   0.28   \n",
      "961   0.11  0.43  0.69  0.43  0.08  0.01  0.82  0.81  0.81  0.37  ...   0.11   \n",
      "667   0.62  0.37  1.00  0.00  0.05  0.03  0.45  0.57  0.41  0.34  ...   0.00   \n",
      "1362  0.13  0.35  0.02  0.96  0.08  0.03  0.39  0.50  0.34  0.59  ...   0.38   \n",
      "23    0.11  0.43  0.04  0.89  0.09  0.06  0.45  0.48  0.31  0.46  ...   0.29   \n",
      "1086  0.12  0.31  0.02  0.89  0.24  0.09  0.76  0.88  0.86  0.21  ...   0.35   \n",
      "1044  0.96  0.32  1.00  0.00  0.11  0.10  0.39  0.56  0.41  0.41  ...   0.51   \n",
      "251   0.10  0.30  0.39  0.67  0.05  0.06  0.38  0.42  0.31  0.77  ...   0.33   \n",
      "1204  0.05  0.41  0.07  0.90  0.11  0.78  0.55  0.53  0.52  0.58  ...   0.30   \n",
      "1695  0.40  0.41  0.16  0.74  0.24  0.16  0.42  0.64  0.39  0.12  ...   0.11   \n",
      "56    0.16  0.44  0.05  0.76  0.53  0.21  0.37  0.49  0.30  0.29  ...   0.34   \n",
      "586   0.11  0.52  1.00  0.15  0.02  0.01  0.58  0.57  0.41  0.33  ...   0.10   \n",
      "80    0.29  0.42  0.27  0.64  0.18  0.31  0.33  0.45  0.28  0.55  ...   0.49   \n",
      "0     0.19  0.33  0.02  0.90  0.12  0.17  0.34  0.47  0.29  0.32  ...   0.29   \n",
      "1029  0.81  0.73  0.07  0.65  0.07  1.00  0.58  0.60  0.40  0.26  ...   0.23   \n",
      "1625  0.74  0.21  0.25  0.58  0.14  0.43  0.30  0.45  0.27  0.44  ...   0.16   \n",
      "323   0.09  0.48  0.59  0.36  0.35  0.26  0.56  0.83  0.61  0.08  ...   0.26   \n",
      "906   0.16  0.51  0.19  0.42  0.96  0.44  0.37  0.54  0.33  0.33  ...   1.00   \n",
      "1037  0.09  0.41  0.07  0.85  0.18  0.15  0.36  0.56  0.38  0.37  ...   0.25   \n",
      "1041  0.10  0.23  0.56  0.54  0.03  0.10  0.18  0.32  0.18  0.85  ...   0.11   \n",
      "384   0.16  0.52  0.39  0.47  0.17  0.73  0.39  0.53  0.34  0.38  ...   0.37   \n",
      "511   0.11  0.46  0.12  0.85  0.03  0.11  0.43  0.51  0.33  0.43  ...   0.14   \n",
      "197   0.20  0.44  1.00  0.19  0.07  0.02  0.46  0.54  0.37  0.45  ...   0.06   \n",
      "1223  0.13  0.46  0.18  0.69  0.06  0.39  0.39  0.44  0.25  0.28  ...   0.15   \n",
      "1120  0.26  0.56  0.07  0.55  1.00  0.25  0.35  0.50  0.28  0.18  ...   0.36   \n",
      "974   0.06  0.44  0.18  0.80  0.20  0.08  0.33  0.38  0.27  0.73  ...   0.12   \n",
      "845   0.16  0.76  0.06  0.31  0.50  0.94  0.49  0.60  0.39  0.24  ...   0.32   \n",
      "\n",
      "       118   119   120   121   122   123  124   125   126  \n",
      "693   0.06  0.19  0.22  0.14  0.02  0.00  0.0  0.98  0.27  \n",
      "630   0.14  0.19  0.34  0.11  0.02  0.50  0.5  0.79  0.08  \n",
      "464   0.16  0.26  0.25  0.07  0.05  0.79  1.0  0.69  0.11  \n",
      "738   0.06  0.24  0.21  0.02  0.01  0.35  1.0  0.50  0.11  \n",
      "739   0.19  0.16  0.07  0.06  0.03  0.99  0.0  0.24  0.08  \n",
      "1536  0.29  0.17  0.19  0.25  0.04  0.45  0.5  1.00  0.09  \n",
      "1345  0.08  0.22  0.11  0.02  0.02  0.81  0.0  0.30  0.15  \n",
      "496   0.06  0.29  0.46  0.05  0.02  0.79  0.0  1.00  0.16  \n",
      "1008  0.02  0.30  0.12  0.00  0.00  0.80  0.0  0.79  0.21  \n",
      "1711  0.17  0.19  0.29  0.14  0.08  0.92  0.5  0.52  0.22  \n",
      "525   0.38  0.24  0.11  0.21  0.01  0.75  0.5  0.77  0.00  \n",
      "1420  0.06  0.26  0.09  0.02  0.02  0.67  0.0  1.00  0.15  \n",
      "305   0.01  0.47  0.24  0.05  0.05  0.91  0.0  0.49  0.69  \n",
      "505   0.22  0.18  0.11  0.35  0.05  0.84  0.0  1.00  0.12  \n",
      "1773  0.02  0.50  0.44  0.05  0.02  0.91  1.0  0.40  0.19  \n",
      "1477  0.07  0.49  0.06  0.06  0.04  0.87  1.0  0.43  0.13  \n",
      "867   0.04  0.29  0.09  0.32  0.06  0.25  0.0  0.70  0.54  \n",
      "513   0.10  0.28  0.13  0.06  0.04  0.60  1.0  0.56  0.16  \n",
      "532   0.23  0.35  0.17  0.23  0.14  0.55  0.5  0.45  0.17  \n",
      "783   0.12  0.11  0.05  0.03  0.00  0.54  1.0  1.00  0.08  \n",
      "1060  0.50  0.38  0.20  0.09  0.10  0.00  1.0  0.16  0.03  \n",
      "1839  0.05  0.23  0.33  0.02  0.02  0.79  0.0  0.65  0.20  \n",
      "1633  0.12  0.68  0.75  0.25  0.32  0.86  0.5  0.33  0.44  \n",
      "553   0.11  0.24  0.63  0.11  0.04  0.55  0.0  0.45  0.19  \n",
      "408   0.07  0.16  0.03  0.04  0.01  0.96  1.0  0.36  0.12  \n",
      "1542  0.06  0.43  0.13  0.05  0.04  0.78  1.0  0.75  0.17  \n",
      "95    0.01  0.89  1.00  0.00  0.01  0.88  0.0  0.35  0.09  \n",
      "1626  0.04  0.47  0.17  0.03  0.02  0.62  0.0  0.72  0.18  \n",
      "68    0.01  0.73  0.28  0.00  0.02  0.64  0.0  1.00  0.23  \n",
      "1303  0.09  0.22  0.03  0.08  0.02  0.83  1.0  0.00  0.10  \n",
      "...    ...   ...   ...   ...   ...   ...  ...   ...   ...  \n",
      "1907  0.18  0.36  0.48  0.53  0.07  0.78  1.0  0.05  0.11  \n",
      "1710  0.09  0.31  0.20  0.08  0.01  0.69  0.0  0.44  0.04  \n",
      "1566  0.30  0.15  0.05  0.32  0.05  0.88  1.0  0.48  0.10  \n",
      "874   0.06  0.18  0.07  0.19  0.05  0.79  0.0  1.00  0.52  \n",
      "961   0.14  0.14  0.03  0.06  0.02  0.74  1.0  1.00  0.12  \n",
      "667   0.38  0.25  1.00  0.17  0.03  0.89  1.0  0.60  0.02  \n",
      "1362  0.09  0.25  0.11  0.06  0.03  0.70  0.0  0.61  0.14  \n",
      "23    0.16  0.12  0.07  0.04  0.01  0.81  1.0  0.56  0.09  \n",
      "1086  0.06  0.31  0.31  0.04  0.02  0.83  0.0  0.77  0.13  \n",
      "1044  0.18  0.83  1.00  0.65  0.72  0.77  0.0  0.45  0.56  \n",
      "251   0.11  0.15  0.07  0.10  0.02  0.73  1.0  0.99  0.15  \n",
      "1204  0.03  0.28  0.17  0.06  0.03  0.70  1.0  0.62  0.35  \n",
      "1695  0.27  0.23  0.01  0.09  0.06  0.83  1.0  0.81  0.08  \n",
      "56    0.08  0.32  0.56  0.07  0.03  0.79  1.0  0.57  0.13  \n",
      "586   0.16  0.12  0.10  0.08  0.03  0.57  1.0  1.00  0.16  \n",
      "80    0.05  0.87  1.00  0.21  0.14  0.69  0.5  0.61  0.34  \n",
      "0     0.12  0.26  0.20  0.06  0.04  0.90  0.5  0.32  0.14  \n",
      "1029  0.72  0.18  0.17  0.58  0.12  0.73  0.5  0.50  0.07  \n",
      "1625  0.45  0.25  0.46  0.68  0.27  0.62  0.5  0.41  0.22  \n",
      "323   0.08  0.19  0.01  0.05  0.01  0.71  0.0  1.00  0.08  \n",
      "906   0.12  0.21  0.45  0.04  0.05  0.64  1.0  0.77  0.19  \n",
      "1037  0.07  0.22  0.16  0.01  0.01  0.83  0.0  0.57  0.09  \n",
      "1041  0.06  0.30  0.20  0.06  0.04  0.93  1.0  1.00  0.26  \n",
      "384   0.03  0.75  0.59  0.08  0.05  0.84  1.0  0.76  0.22  \n",
      "511   0.06  0.31  0.11  0.06  0.02  0.88  0.5  0.51  0.14  \n",
      "197   0.18  0.18  0.35  0.11  0.00  0.80  0.0  1.00  0.02  \n",
      "1223  0.19  0.11  0.01  0.16  0.02  0.66  0.0  0.27  0.10  \n",
      "1120  0.22  0.19  0.26  0.09  0.07  0.72  0.5  0.37  0.16  \n",
      "974   0.02  0.46  0.32  0.03  0.03  0.75  0.0  0.54  0.31  \n",
      "845   0.05  0.49  0.13  0.04  0.03  0.91  0.5  0.86  0.11  \n",
      "\n",
      "[80 rows x 122 columns]\n"
     ]
    }
   ],
   "source": [
    "print (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Alpha Value:  0.01\n",
      "RMSE (ENET CV reg.) = 0.161381503338\n"
     ]
    }
   ],
   "source": [
    "preds = enetcv.fit(X_train, y_train).predict(X_test)\n",
    "print('Optimal Alpha Value: ', enetcv.alpha_)\n",
    "print('RMSE (ENET CV reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 (ENET reg.) = -0.0136555307053\n"
     ]
    }
   ],
   "source": [
    "# use r2_score\n",
    "# why score<0?\n",
    "from sklearn.metrics import r2_score\n",
    "preds = enet.fit(X_train, y_train).predict(X_test)\n",
    "print('R^2 (ENET reg.) =', r2_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.        ,  0.08672231, -0.22257432,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        ,  0.        ,  0.05102937, -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.0700438 ,  0.        ,\n",
       "        0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.03387024,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.04775612, -0.14505711,\n",
       "       -0.03623363, -0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.15742425,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        ,  0.        ,  0.        , -0.        ,\n",
       "       -0.        ,  0.        , -0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.04156342, -0.        , -0.        ,  0.00067274,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        ,  0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.11619895,  0.        , -0.        , -0.        ,  0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -0.        ,\n",
       "       -0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        ,  0.01830395,\n",
       "       -0.        ,  0.        ])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "enet = ElasticNet(alpha=0.01, l1_ratio=0.7)\n",
    "\n",
    "enet.fit(X_train, y_train)\n",
    "enet.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Task 2: Carry out Regularised Regression\n",
    "\n",
    "1. Run all three forms of reularised regression on the Boston Housing DataSet\n",
    "2. What do the coefficients mean?\n",
    "3. What would you advise someone living in Boston to try and raise the value of their home?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso model:  -3.707 * LSTAT + 2.992 * RM + -1.757 * PTRATIO + -1.081 * DIS + -0.7 * NOX + 0.631 * B + 0.54 * CHAS + -0.236 * CRIM + 0.081 * ZN + -0.0 * INDUS + -0.0 * AGE + 0.0 * RAD + -0.0 * TAX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:16: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_boston\n",
    "  \n",
    "boston = load_boston()\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(boston[\"data\"])\n",
    "Y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]\n",
    "  \n",
    "lasso = Lasso(alpha=.3)\n",
    "lasso.fit(X, Y)\n",
    "\n",
    "#A helper method for pretty-printing linear models\n",
    "def pretty_print_linear(coefs, names = None, sort = False):\n",
    "    if names == None:\n",
    "        names = [\"X%s\" % x for x in range(len(coefs))]\n",
    "    lst = zip(coefs, names)\n",
    "    if sort:\n",
    "        lst = sorted(lst,  key = lambda x:-np.abs(x[0]))\n",
    "    return \" + \".join(\"%s * %s\" % (round(coef, 3), name)\n",
    "                                   for coef, name in lst)\n",
    "  \n",
    "print(\"Lasso model: \", pretty_print_linear(lasso.coef_, names, sort = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     5     6     7     8     9     10    11    12    13    14   ...    117  \\\n",
       "0   0.19  0.33  0.02  0.90  0.12  0.17  0.34  0.47  0.29  0.32  ...   0.29   \n",
       "16  0.15  0.31  0.40  0.63  0.14  0.06  0.58  0.72  0.65  0.47  ...   0.22   \n",
       "20  0.25  0.54  0.05  0.71  0.48  0.30  0.42  0.48  0.28  0.32  ...   0.36   \n",
       "21  1.00  0.42  0.47  0.59  0.12  0.05  0.41  0.53  0.34  0.33  ...   1.00   \n",
       "23  0.11  0.43  0.04  0.89  0.09  0.06  0.45  0.48  0.31  0.46  ...   0.29   \n",
       "\n",
       "     118   119   120   121   122   123  124   125   126  \n",
       "0   0.12  0.26  0.20  0.06  0.04  0.90  0.5  0.32  0.14  \n",
       "16  0.06  0.39  0.84  0.06  0.06  0.91  0.5  0.88  0.26  \n",
       "20  0.09  0.46  0.05  0.09  0.05  0.88  0.5  0.76  0.13  \n",
       "21  1.00  0.07  0.15  1.00  0.35  0.73  0.0  0.31  0.21  \n",
       "23  0.16  0.12  0.07  0.04  0.01  0.81  1.0  0.56  0.09  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.20\n",
       "16    0.49\n",
       "20    0.34\n",
       "21    0.69\n",
       "23    0.63\n",
       "Name: 127, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n"
     ]
    }
   ],
   "source": [
    "print (boston.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Alpha Value:  1.0\n",
      "RMSE (Ridge CV reg.) = 0.163129782343\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_boston\n",
    "  \n",
    "boston = load_boston()\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(boston[\"data\"])\n",
    "Y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]\n",
    "  \n",
    "alpha_range = 10.**np.arange(-2, 3)\n",
    "rregcv = RidgeCV(alphas=alpha_range, normalize=True)\n",
    "rregcv.fit(X_train, y_train)\n",
    "\n",
    "preds = rregcv.predict(X_test)\n",
    "print('Optimal Alpha Value: ',rregcv.alpha_)\n",
    "print ('RMSE (Ridge CV reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Alpha Value:  0.01\n",
      "RMSE (Lasso CV reg.) = 0.198165225429\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_boston\n",
    "  \n",
    "boston = load_boston()\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(boston[\"data\"])\n",
    "Y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]\n",
    "  \n",
    "alpha_range = 10.**np.arange(-2, 3)\n",
    "lascv = LassoCV(alphas=alpha_range, normalize=True)\n",
    "lascv.fit(X_train, y_train)\n",
    "\n",
    "preds = lascv.predict(X_test)\n",
    "print('Optimal Alpha Value: ',lascv.alpha_)\n",
    "print ('RMSE (Lasso CV reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Alpha Value:  0.01\n",
      "RMSE (ENET reg.) = 0.160945198724\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_boston\n",
    "  \n",
    "boston = load_boston()\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(boston[\"data\"])\n",
    "Y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]\n",
    "  \n",
    "alpha_range = 10.**np.arange(-5, 6)\n",
    "enetcv = ElasticNetCV(alphas=alpha_range, l1_ratio=0.7) \n",
    "enetcv.fit(X_train, y_train)\n",
    "\n",
    "preds = enet.predict(X_test)\n",
    "print('Optimal Alpha Value: ',enetcv.alpha_)\n",
    "print ('RMSE (ENET reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENET model:  -3.711 * LSTAT + -3.014 * DIS + 2.697 * RM + 2.404 * RAD + -2.031 * PTRATIO + -1.956 * NOX + -1.835 * TAX + 1.023 * ZN + -0.887 * CRIM + 0.85 * B + 0.691 * CHAS + 0.042 * INDUS + -0.0 * AGE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:16: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_boston\n",
    "  \n",
    "boston = load_boston()\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(boston[\"data\"])\n",
    "Y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]\n",
    "  \n",
    "enet = ElasticNet(alpha=.01)\n",
    "enet.fit(X, Y)\n",
    "\n",
    "#A helper method for pretty-printing linear models\n",
    "def pretty_print_linear(coefs, names = None, sort = False):\n",
    "    if names == None:\n",
    "        names = [\"X%s\" % x for x in range(len(coefs))]\n",
    "    lst = zip(coefs, names)\n",
    "    if sort:\n",
    "        lst = sorted(lst,  key = lambda x:-np.abs(x[0]))\n",
    "    return \" + \".join(\"%s * %s\" % (round(coef, 3), name)\n",
    "                                   for coef, name in lst)\n",
    "  \n",
    "print(\"ENET model: \", pretty_print_linear(enet.coef_, names, sort = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
