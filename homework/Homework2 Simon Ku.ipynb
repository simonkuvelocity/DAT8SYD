{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYD DAT 8 Homework 2 - Visualisation and Regression\n",
    "\n",
    "## Homework - Due Friday 30th June\n",
    "\n",
    "#### Setup\n",
    "* Signup for an AWS account\n",
    "\n",
    "#### Communication\n",
    "* Imagine you are trying to explain to someone what Linear Regression is - but they have no programming/maths experience? How would you explain the overall process, what a p-value means and what R-Squared means?\n",
    "* Read the paper [Useful things to know about machine learning]( https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf). \n",
    "    * What have we covered so far from this paper? \n",
    "    * Explain sections 6-13 in your own words\n",
    "\n",
    "#### Machine Learning\n",
    "* Describe 3 ways we can select what features to use in a model\n",
    "* Complete the first 3 exercises from Chapter 3 of Introduction to Statistical Learning in Python\n",
    "\n",
    "#### Course Project\n",
    "* For the following setup a new github repository for your project and share it with Alasdair and Ian over Slack.\n",
    "* Load the data you have gathered for your project into Python and run some summary statistics over the data. Are there any interesting features of the data that jump out? (Include the code)\n",
    "* Draft/Sketch (or wireframe) some data visualisations that would be useful for you to explore your data set\n",
    "* Are there any regresion or clustering techniques you could use in your project? Write them down (with the corresponding scikit learn function) and what you think you would get out of it. Try it out if you get a chance.\n",
    "\n",
    "\n",
    "**Instructions: copy this file and append your name in the filename, e.g. Homework2_ian_hansel.ipynb.\n",
    "Then commit this in your local repository, push it to your github account and create a pull request so I can see your work. Remeber if you get stuck to look at the slides going over Fork, Clone, Commit, Push and Pull request.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SYD DAT 8 Homework 2 - Visualisation and Regression - Simon Ku\n",
    "\n",
    "## Homework - Due Friday 30th June\n",
    "\n",
    "#### Setup\n",
    "* Signup for an AWS account\n",
    "\n",
    "#### Communication\n",
    "* Imagine you are trying to explain to someone what Linear Regression is - but they have no programming/maths experience? How would you explain the overall process, what a p-value means and what R-Squared means?\n",
    "\n",
    "#### Simon:\n",
    "* Talk to a 10-year-old girl about linear regression - Assume a tree growth is some proportion as you pour the amount of water every day.  If you double the amount you pour water each day, the tree will grow twice fast as it would be.\n",
    "About R-squared?  R-squared is a number between 0 and 1. If you do not do anything, the tree will die, so the R-squared is zero. If you pour lots lots of water, the  R-squared is 1; and if you pour only some days , the R-squared is a number somewhere between 0 and 1.\n",
    "\n",
    "* Read the paper [Useful things to know about machine learning]( https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf). \n",
    "    * What have we covered so far from this paper? \n",
    "    * Explain sections 6-13 in your own words\n",
    "\n",
    "#### Simon:\n",
    "In this course so far we have broadly covered:\n",
    "-\tRegression and Classification\n",
    "-\tModel visualisation and evaluations\n",
    "-\tRegularisation and Bias-variance, i.e. under- or over-fitting\n",
    "-\tSampling data different ways to the model developed can be generalised\n",
    "-\tViews from industry practitioners / guest speakers\n",
    "-\t\n",
    "-\tSection 6: Challenge of high dimension classification but progress made in ‘blessing of non-uniformity’\n",
    "-\tSection 7:  Theoretical results has made so much progress recently to help ML learners and practitioners to achieve accuracies but loose upper bound still take a lot of times to obtain asymptotical optimal outcomes.\n",
    "-\tSection 8: Feature selection / engineering  to reduce large amount of inputs is a key for an effective machine learning\n",
    "-\tSection 9: Any smart algorithm is desirable but large data sets for training and learning is beneficial as ML is still all about letting data itself to the heavy lifting fundamental tasks.\n",
    "-\tSection 10: Allow data learn more models than a single one even this is the ‘best’ one.  Blending of top models via auto ML may be a better way to approach modelling.\n",
    "-\tSection 11: Simplicity is no guarantee of accuracy. Ensembles models seem to improve model outcomes.\n",
    "-\tSection 12: Representation or approximately represented learns may not lead to optima of global evaluation function as learn (e.g. linear) only may be a very small subset of hypothesis space (e.g. exponential)\n",
    "-\tSection 13: Correlation of variables is observable and exists, but causality may exist and is hard to prove without proper experimental data.\n",
    "    \n",
    "#### Machine Learning\n",
    "* Describe 3 ways we can select what features to use in a model\n",
    "* Complete the first 3 exercises from Chapter 3 of Introduction to Statistical Learning in Python (R)\n",
    "\n",
    "#### Simon:\n",
    "* Lasso regularization panelises unnecessary variables into the model\n",
    "* Ridge regularization panelises large coefficient should a standardised variable is selected\n",
    "* ENet (Elastic Net) is the balance of above two and it is recommended\n",
    "\n",
    "##### Chapter 3 \n",
    "Q1.   In Table 3.4 (p.120), the null hypothesis for TV H0 is that given the presence of radio and newspaper ads, \n",
    "TV ads have no effect on sales (y-value), or beta_TV = 0. \n",
    "Similarly, the null hypothesis for radio H0 is that given the presence of TV and newspaper ads, \n",
    "radio ads have no effect on sales or beta_radio = 0. \n",
    "And finally the null hypothesis for newspaper H0 is that given the presence of TV and radio ads, newspaper ads \n",
    "have no effect on sales or beta_newspaper = 0.\n",
    "\n",
    "The low p-values generally reject the null hypotheses, i.e. the betas are suggested nonzero. In this case, zeros of beta_TV, beta_radio are false.   The high p-value of newspaper suggests that the null hypothesis is true for newspaper and printing is not affecting on the sales.\n",
    "\n",
    "Q2. In KNN classification, the output is a class membership. An object is classified by a majority vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors. In KNN regression, the output is the functional value for the object. This value may be the average of the values of its k nearest neighbors\n",
    "\n",
    "Q3. From the given information, the prediction of y may be written as \n",
    "Yhat = 50+ 20(GPA)+0.07(IQ)+ 35(Gender)+ 0.01(GPA)(IQ)- 10(GPA)(Gender)\n",
    "\n",
    "(a) For a fixed value of IQ and GPA, only two terms in Yhat is varied by Gender:\n",
    "    \n",
    "Yhat(Gender=Female)= 50+20(GPA)+0.07(IQ)+ 0.01(GPA)(IQ)+35(1)-10(GPA)(1);\n",
    "\n",
    "Yhat(Gender=Male)= 50+20(GPA)+0.07(IQ)+ 0.01(GPA)(IQ)+35(0)-10(GPA)(0) so\n",
    "\n",
    "Diff =Yhat(Gender=Female) - Yhat(Gender=Male)=35-10(GPA).  Therefore, when GPA=3.5 or high, the Diff<0, i.e. female earn is less than male earn.  This leads to (iii) is true.\n",
    "\n",
    "(b) Yhat(Gender = 1, IQ = 110, GPA = 4.0)\n",
    "= 50 + 20 (4) + 0.07 (110) + 35 + 0.01 (4)(110) - 10 (4) = 137.1 units.\n",
    "\n",
    "(c) False. Evidence of effect significance of a coefficient in the regression is determined by the p-value of this term (usually <0.05) not the magnitude of the coefficient.\n",
    "\n",
    "\n",
    "#### Course Project\n",
    "* For the following setup a new github repository for your project and share it with Alasdair and Ian over Slack.\n",
    "* Load the data you have gathered for your project into Python and run some summary statistics over the data. Are there any interesting features of the data that jump out? (Include the code)\n",
    "* Draft/Sketch (or wireframe) some data visualisations that would be useful for you to explore your data set\n",
    "* Are there any regresion or clustering techniques you could use in your project? Write them down (with the corresponding scikit learn function) and what you think you would get out of it. Try it out if you get a chance.\n",
    "\n",
    "\n",
    "**Instructions: copy this file and append your name in the filename, e.g. Homework2_ian_hansel.ipynb.\n",
    "Then commit this in your local repository, push it to your github account and create a pull request so I can see your work. Remeber if you get stuck to look at the slides going over Fork, Clone, Commit, Push and Pull request.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
